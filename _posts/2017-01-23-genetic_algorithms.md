Natural Selection in Machine Learning
================

### The Genetic Algorithms

The Theory of Evolution indicates that countless life forms, many with incredibly complex biologial structures and metabolic activities, have emerged purely by chance on this relatively very young planet we call Earth. Although not often realized due to its large time scale, the process of natural selection is one with very high adaptivity as well as great efficiency. This idea was fascinating to the 8th grade me and was essentially what got me into life science in my undergrad.

As a Data Science student, I recently learnt about a machine learning method inspired by the processes of evolution, but has applications to non-biological fields as well! The Genetic Algorithm is a subset of evolutionary algorithms that employs biological operators such as natural selection, mutation, and crossover or recombination. The algorithms start with a population of randomly generated individual solutions. Each solution or object has a number of common features that affect its performance in the targeted problem. The collection of features for each individual is often summarised into a string of digits called the Chromosome, where each digit (Gene) represents a single feature. For solutions with binary features, the chromosomes of different solutions may look similar to these:

Generation 0:

| solution | gene0 | gene1 | gene2 | gene3 | gene4 | gene5 | gene6 | gene7 | gene8 | gene9 |
|----------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|
| a        | 1     | 1     | 0     | 0     | 0     | 0     | 0     | 1     | 0     | 0     |
| b        | 0     | 0     | 0     | 0     | 1     | 1     | 1     | 1     | 1     | 1     |
| c        | 0     | 1     | 1     | 1     | 1     | 0     | 0     | 1     | 1     | 1     |

The randomly generated solutions are evaluated by their genes using a fitness function. Then, a new generation of solutions is created according to this evaluation. Individuals ranked higher in the original population are given a greater probability to leave copies of its genes in chromosomes of the successive generation. This design aligns with the concept of "survival of the fittest" in the theory of evolution. However, biological fitness is defined by the chance to reproduce, whereas in genetic algorithms fitness defines the chance to reproduce.

The characteristic factor that distinguishes a genetic algorithm from evolutionary algorithms in general is its mimicking of recombination between chromosomes. When determining genes in the next generation, top ranked solutions in the current generation are used as parents to make offsprings. This is done by making random recombinations from chromosomes of well performed individuals. For example, if solutions b and c above are top ranked in generation 0, an offspring in generation 1 may have the chromosome as follows:

Generation 1:

| solution | gene0 | gene1 | gene2 | gene3 | gene4 | gene5 | gene6 | gene7 | gene8 | gene9 |
|----------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|
| d        | 0     | 0     | 0     | 0     | 1     | 1     | 0     | 1     | 1     | 1     |

which is generated by attaching the first 6 digits (genes) of solution b to the last 4 digits of solution c. This is done repeatedly in the expectation that the new generation may combine the advantageous features of winning solutions in the previous generation, and individual solutions will perform better than either of their parents on average.

However, if only the best solutions are used to generate offsprings, the algorithm will very likely converge prematurely to a local optimum. To prevent this from happening, the concept of mutation is introduced. For each generation, a small proportion of solutions are generated not by recombination, but by modifying the parental genes with some low probability. While the average fitness may be lowered by mutation, the genetic diversity of a population is retained in each generation for greater adaptivity. The mutation rate has an influence on the algorithm too: A too small mutation rate will cause genetic drifting and loss of diversity, but a large mutation rate may delete close to optimal solutions and cause the algorithm to never converge.

Nevertheless, the genetic algorithm made no guarantee that a global optimum will be reached. Rather, it is a metaheuristic that provides solutions good enough for some practical problems with limited information or computation power. The exact complexity depends on the difficulty to compute a workable fitness function, which can be very time consuming and depends on the nature of each problem. In practice, there could be thousands of candidate solutions with hundreds of genes, which really challenges the algorithm's scalability.

There are many variations of the algorithm for better performance in terms of efficiency and accuracy. For example, we can only evaluate a randomly selected subset of each generation for ranking, or apply fitness approximation to save computation time. Moreover, an elite solution can be set so that the fittest individual in a population is never modified until a better solution replaces it.

The genetic algorithm is simple to implement and interpret, and can be very effective in solving discontinuous or non-differentiable problems. Although the efficiency of the algorithm is limited by number of candidates in each generation, number of generations, and fitness function evaluation, simple genetic algorithms can often solve difficult problems. I will share below a simple demonstration, and link a few very fun examples.

### Demonstration in R

For demonstration I will use the R package for genetic algorithms GA. The following code is based on the vignette of GA package:

``` r
# install.packages("GA")
library(GA)
```

    ## Loading required package: foreach

    ## Loading required package: iterators

    ## Package 'GA' version 3.0.2

    ## Type 'citation("GA")' for citing this R package in publications.

Let's start with some basics. The genetic algorithm can be used to optimize simple objective functions with only one explanatory variable. I will try to optimize something looking weird and not easily differentiable:

``` r
lb <- -3
ub <- 3
f <- function(x) abs(x)*cos(x+1)
curve(expr = f,from = lb,to = ub,n=1000)
```

![](/images/fig1.png)

To do this, we randomly sample a population within the domain of the problem \((-3,3)\). The solutions have only one feature, x, which can be mutated and crossed over in each generation. The `ga` function in this package uses a population of 50 individuals for 100 generations, and has 2 elite solutions which keeps the current best fitness scores. The evolution process is summarized and plotted below:

``` r
GA <- ga(type = "real-valued", fitness = f, min = lb, max = ub, 
         monitor = FALSE)
summary(GA)
```

    ## +-----------------------------------+
    ## |         Genetic Algorithm         |
    ## +-----------------------------------+
    ## 
    ## GA settings: 
    ## Type                  =  real-valued 
    ## Population size       =  50 
    ## Number of generations =  100 
    ## Elitism               =  2 
    ## Crossover probability =  0.8 
    ## Mutation probability  =  0.1 
    ## Search domain = 
    ##     x1
    ## Min -3
    ## Max  3
    ## 
    ## GA results: 
    ## Iterations             = 100 
    ## Fitness function value = 1.32179 
    ## Solution = 
    ##             x1
    ## [1,] -1.567818

``` r
plot(GA)
```

![](/images/fig2.png)

The optimized solution (maximum) found is:

``` r
curve(f, lb, ub, n = 1000)
points(GA@solution, GA@fitnessValue, col = 'red')
```

![](/images/fig3.png)

To find the minimum value, add a `-` sign in front of the fitness function as such:

``` r
GA <- ga(type = "real-valued", fitness = function(x) -f(x), min = lb, max = ub, 
         monitor = FALSE)
curve(f, lb, ub, n = 1000)
# notice the minus sign in front of calculated fitness value because the fitness function is the negative of objective function
points(GA@solution, -GA@fitnessValue, col = 'blue', pch = 100)
```

![](/images/fig4.png)

Moving on to a 2D space search. The problem is a replication of the [MathWorks](https://www.mathworks.com/videos/what-is-a-genetic-algorithm-100904.html)' genetic algorithm demonstration in R:

``` r
lb <- -3
ub <- 1
g <- function(x,y) 3*(1-x)^2*exp(-(x^2)) - (y+1)^2 - 10*(x/5 - x^3 - y^5)*exp(-x^2 - y^2) - 1/3*exp(-(x+1)^2 - y^2)

x <- y <- seq(lb, ub, by = 0.1)
f <- outer(x, y, g)
persp3D(x, y, f, theta = 50, phi = 20, color.palette = bl2gr.colors)
```

![](/images/fig5.png)

The problem has a couple local minima and one global minima in the domain of interest. To view this more clearly:

``` r
filled.contour(x, y, f, color.palette = bl2gr.colors)
```

![](/images/fig6.png)

The genetic algorithm can be applied by starting with randomly selected points, and mutate around points with promising fitness values. The code is very similar to the previous example for minimization:

``` r
GA <- ga(type = "real-valued", 
         fitness =  function(x) -g(x[1], x[2]),
         min = c(lb, lb), max = c(ub, ub))

filled.contour(x, y, f, color.palette = bl2gr.colors, 
  plot.axes = { axis(1); axis(2); 
                points(GA@solution[,1], GA@solution[,2], 
                       pch = 3, cex = 2, col = "white", lwd = 2) }
)
```

![](/images/fig7.png)

The evolution process is summarized and plotted:

``` r
summary(GA)
```

    ## +-----------------------------------+
    ## |         Genetic Algorithm         |
    ## +-----------------------------------+
    ## 
    ## GA settings: 
    ## Type                  =  real-valued 
    ## Population size       =  50 
    ## Number of generations =  100 
    ## Elitism               =  2 
    ## Crossover probability =  0.8 
    ## Mutation probability  =  0.1 
    ## Search domain = 
    ##     x1 x2
    ## Min -3 -3
    ## Max  1  1
    ## 
    ## GA results: 
    ## Iterations             = 100 
    ## Fitness function value = 6.459098 
    ## Solution = 
    ##             x1        x2
    ## [1,] 0.3065549 -1.620975

``` r
plot(GA)
```

![](/images/fig8.png)

I will do one more boring demonstration before sharing something much more fun. It is well known that Darwin developed his theory of evolution partially by observing his famous [finches](http://www.rpgroup.caltech.edu/courses/Evolution_GIST_2013/files_2013/articles/FinchesSulloway.pdf) on different islands. The GA package borrowed this idea of isolated evolution to further avoid prematured convergence. The population is devided into a number of subpopulations as defined to live on their own "islands". Except for rare occasions, the genetic materials are only exchanged within each group and not between different islands. The same problem is examined using this approach on a larger domain:

``` r
lb <- lb - 10
ub <- ub + 10
GA <- gaisl(type = "real-valued", 
            fitness =  function(x) -g(x[1], x[2]),
            min = c(lb,lb), max = c(ub,ub), 
            popSize = 400, 
            # maxiter = 1000, run = 100,
            numIslands = 2, 
            # proportion of individuals that migrates
            migrationRate = 0.1,
            # frequency of migration happening
            migrationInterval = 50)
plot(GA, log = "x")
```

![](/images/fig9.png)

It is seen that the evolutionary paths for the two subpopulations are quite similar to each other. This is due to the simplicity of the problem. For practical, complex problems, the plots will be more diverged. Another advantage of the island evolution approach is that the calculation is done in parallel by default. In the GA package, parallelism can be easily applied to boost the algorithm's performance in terms of time complexity.

### Super Fun Examples

The genetic algorithm has very broad applications in a great number of areas. I have encountered a few super fun examples while writing this post. The first example I can't wait anymore to share is [the Genetic Algorithm 2D car thingy](http://rednuht.org/genetic_cars_2/) written in HTML5. This page creates a population of cars with different shapes, sizes and wheels to compete with each other on a randomly generated landscape. The fitness of cars are determined by the distance they are able to travel, elevation, and survival time before stuck. The goal here is to create the ultimate 2D car thingy that can travel the farthest with the fastest speed. On this page, you can set not only the mutation rate, size and the number of elite clones, but also the gravity to different planets and mutate the landscape for each generation. This thing is addicting to watch.

Here is a similar but somewhat simplified [video](https://www.youtube.com/watch?v=uxourrlPlf8).

Another example is to [approximate Mona Lisa](https://www.youtube.com/watch?v=rGt3iMAJVT8) with 150 circles of various positions, colors and sizes. This example is not as fun to watch as the 2D car thingy (seriously it is fun), as the approximation is very slow and the final result does not seem to be impressive. But keep in mind what we see is a Machine Learning algorithm inspired by biological processes applied to the field of Fine Arts. Still, it is noticed that the genetic algorithm took 332193 generations of circles to get where it is, and the nose of "Mona Lisa" is literally a black dot. This indicated that the scalability is really limited when complex problems are encountered. Therefore, genetic algorithms often focus on small components of a complex problem in practice.

However, this difficulty can be partially overcomed by increasing the population size. A similar problem in tackled in the [Evolving Darwin](https://www.youtube.com/watch?v=dO05XcXLxGs) example, where a picture of Darwin is approximated with 1000 ellipses instead of 150 circles. The final product is almost identical to the original picture. However, the evolution took approximately the same number of generations as the Mona Lisa problem, and each step probably took longer in comparison due to larger population size. Thus, increasing the population makes the the approximation more accurate, but more time consuming.

Some of other fun examples that employed genetic algorithms as well as neural network are listed below: - [another cool image reproducing example](https://www.youtube.com/watch?v=iV-hah6xs2A) - [training 2D robot fighters](https://www.youtube.com/watch?v=u2t77mQmJiY) - [funny ladders learning to stand](https://www.youtube.com/watch?v=lPQnVEnFTgY) - [evolving kangaroos](https://www.youtube.com/watch?v=m4E9sj9vH1I)

References:

Oliveto, Pietro S., Jun He, and Xin Yao. "Time complexity of evolutionary algorithms for combinatorial optimization: A decade of results." International Journal of Automation and Computing 4.3 (2007): 281-293.

Y. Rabinovich, A. Wigderson. Techniques for bounding the convergence rate of genetic algorithms. Random Structures Algorithms, vol. 14, no. 2, 111-138, 1999.

Ashlock, D. (2006), Evolutionary Computation for Modeling and Optimization, Springer, ISBN 0-387-22196-4.

Wikipedia contributors. "Metaheuristic." Wikipedia, The Free Encyclopedia. Wikipedia, The Free Encyclopedia, 27 Dec. 2016. Web. 23 Jan. 2017.

Wikipedia contributors. "Genetic algorithm." Wikipedia, The Free Encyclopedia. Wikipedia, The Free Encyclopedia, 5 Jan. 2017. Web. 23 Jan. 2017.

Luca Scrucca (2013). GA: A Package for Genetic Algorithms in R. Journal of Statistical Software, 53(4), 1-37. URL <http://www.jstatsoft.org/v53/i04/>.

Luca Scrucca (2016). On some extensions to GA package: hybrid optimisation, parallelisation and islands evolution. Submitted to R Journal. Pre-print available at arXiv URL <http://arxiv.org/abs/1605.01931>.
